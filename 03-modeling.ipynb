{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression, RidgeCV, LassoCV\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./CSVs/all_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop passenger to frankfurt\n",
    "df = df[df['book_title'].str.lower() != 'passenger to frankfurt'].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop the features that aren't normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['book_title', 'book_text', 'year_written', 'sentence_count',\n",
       "       'word_count', 'syllable_count', 'flesch_reading_ease',\n",
       "       'avg_words_per_sentence', 'avg_syllables_per_word', 'stemmed_text',\n",
       "       'unique_word_count', 'unique_words_%', 'total_adj_count',\n",
       "       'unique_adj_count', 'total_noun_count', 'unique_noun_count', 'thing',\n",
       "       '%_thing', 'something', '%_something', 'anything', '%_anything',\n",
       "       'stuff', '%_stuff', 'lot', '%_lot', 'very', '%_very',\n",
       "       'repeated_trigrams', 'total_pos_sentences', 'total_neu_sentences',\n",
       "       'total_neg_sentences', '%_pos_sentences', '%_neu_sentences',\n",
       "       '%_neg_sentences', 'stemmed_removed_stopwords', 'only_stopwords',\n",
       "       'stopwords_count', '%_stop_words', '%_repeated_trigrams',\n",
       "       '%_unique_adj', '%_unique_noun', '%_adj_in_text', '%_noun_in_text'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop the columns that are just counts (not normalized):\n",
    "to_drop = ['book_title', 'book_text', 'sentence_count', \n",
    "              'word_count', 'syllable_count','stemmed_text',\n",
    "              'unique_word_count', 'unique_words_%', 'total_adj_count',\n",
    "              'unique_adj_count', 'total_noun_count', 'unique_noun_count', \n",
    "              'thing','anything', 'stuff', 'something', 'lot','very',\n",
    "              'repeated_trigrams', 'total_pos_sentences',\n",
    "              'total_neu_sentences', 'total_neg_sentences', 'stemmed_removed_stopwords',\n",
    "              'only_stopwords', 'stopwords_count']\n",
    "\n",
    "train = df.drop(to_drop, axis=1)\n",
    "train['decade_written'] = train['year_written'].map(lambda x: int(str(x)[:3] + '0'))\n",
    "\n",
    "short_stories = short_stories.drop(to_drop, axis=1)\n",
    "short_stories['decade_written'] = short_stories['year_written'].map(lambda x: int(str(x)[:3] + '0'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv('./CSVs/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['year_written', 'flesch_reading_ease', 'avg_words_per_sentence',\n",
       "       'avg_syllables_per_word', '%_thing', '%_something', '%_anything',\n",
       "       '%_stuff', '%_lot', '%_very', '%_pos_sentences', '%_neu_sentences',\n",
       "       '%_neg_sentences', '%_stop_words', '%_repeated_trigrams',\n",
       "       '%_unique_adj', '%_unique_noun', '%_adj_in_text', '%_noun_in_text',\n",
       "       'decade_written'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make X and y and scale the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.drop(['year_written', 'decade_written'], axis=1)\n",
    "y = train['decade_written']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#need to stratify because classes are uneven\n",
    "X_train, X_test,y_train, y_test = train_test_split(X, y, stratify=y, random_state = 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled = sc.fit_transform(X_train)\n",
    "X_test_scaled = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline\n",
    "The dummy regressor always predicts the mean, which is 1941"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1941.063829787234"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.astype(int).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DummyRegressor()"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy = DummyRegressor(strategy='mean')\n",
    "dummy.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline:\n",
      "Train Score: 0.0 \n",
      "Test Score: -0.00017466128187137997\n"
     ]
    }
   ],
   "source": [
    "print('Baseline:''\\nTrain Score:', dummy.score(X_train_scaled, y_train),'\\nTest Score:', dummy.score(X_test_scaled, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Logistic Regression\n",
      "Train Score: 0.9361702127659575 \n",
      "Test Score: 0.25\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train_scaled, y_train)\n",
    "print('Model: Logistic Regression''\\nTrain Score:', logreg.score(X_train_scaled, y_train),'\\nTest Score:', logreg.score(X_test_scaled, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Linear Regression\n",
      "Train Score: 0.8771176939829655 \n",
      "Test Score: 0.6966793509800457\n"
     ]
    }
   ],
   "source": [
    "linear = LinearRegression()\n",
    "linear.fit(X_train_scaled, y_train)\n",
    "print('Model: Linear Regression''\\nTrain Score:', linear.score(X_train_scaled, y_train),'\\nTest Score:', linear.score(X_test_scaled, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Lasso Regression \n",
      "Train Score: 0.8467731296586589 \n",
      "Test Score: 0.7270014933020995\n"
     ]
    }
   ],
   "source": [
    "lasso = LassoCV(cv=5)\n",
    "lasso.fit(X_train_scaled, y_train)\n",
    "print('Model: Lasso Regression', '\\nTrain Score:', lasso.score(X_train_scaled, y_train),'\\nTest Score:', lasso.score(X_test_scaled, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Ridge Regression\n",
      "Train Score: 0.834568688969893 \n",
      "Test Score: 0.7114815582090936\n"
     ]
    }
   ],
   "source": [
    "ridge = RidgeCV(cv=5)\n",
    "ridge.fit(X_train_scaled, y_train)\n",
    "print('Model: Ridge Regression''\\nTrain Score:', ridge.score(X_train_scaled, y_train),'\\nTest Score:', ridge.score(X_test_scaled, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Random Forest Regression\n",
      "Train Score: 0.944582666980245 \n",
      "Test Score: 0.45108346456692827\n"
     ]
    }
   ],
   "source": [
    "forest = RandomForestRegressor()\n",
    "forest.fit(X_train_scaled, y_train)\n",
    "print('Model: Random Forest Regression''\\nTrain Score:', forest.score(X_train_scaled, y_train),'\\nTest Score:', forest.score(X_test_scaled, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Gradient Boost\n",
      "Train Score: 0.9999568791437801 \n",
      "Test Score: 0.3559345265410766\n"
     ]
    }
   ],
   "source": [
    "boost = GradientBoostingRegressor(min_samples_split = 5)\n",
    "boost.fit(X_train_scaled, y_train)\n",
    "print('Model: Gradient Boost''\\nTrain Score:', boost.score(X_train_scaled, y_train),'\\nTest Score:', boost.score(X_test_scaled, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_years = df.loc[y_test.index]['year_written'].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = pd.Series(lasso.predict(X_test_scaled)).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_and_real = pd.concat([preds, real_years], axis=1)\n",
    "preds_and_real.columns = ['predictions', 'actual']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_and_real['difference'] = abs(preds_and_real['actual'] - preds_and_real['predictions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predictions</th>\n",
       "      <th>actual</th>\n",
       "      <th>difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1976</td>\n",
       "      <td>1973</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1936</td>\n",
       "      <td>1936</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1943</td>\n",
       "      <td>1956</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1945</td>\n",
       "      <td>1949</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1929</td>\n",
       "      <td>1935</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1936</td>\n",
       "      <td>1931</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1930</td>\n",
       "      <td>1927</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1925</td>\n",
       "      <td>1922</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1932</td>\n",
       "      <td>1932</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1934</td>\n",
       "      <td>1941</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1943</td>\n",
       "      <td>1961</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1946</td>\n",
       "      <td>1940</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1944</td>\n",
       "      <td>1955</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1943</td>\n",
       "      <td>1954</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1932</td>\n",
       "      <td>1944</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1952</td>\n",
       "      <td>1963</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    predictions  actual  difference\n",
       "0          1976    1973           3\n",
       "1          1936    1936           0\n",
       "2          1943    1956          13\n",
       "3          1945    1949           4\n",
       "4          1929    1935           6\n",
       "5          1936    1931           5\n",
       "6          1930    1927           3\n",
       "7          1925    1922           3\n",
       "8          1932    1932           0\n",
       "9          1934    1941           7\n",
       "10         1943    1961          18\n",
       "11         1946    1940           6\n",
       "12         1944    1955          11\n",
       "13         1943    1954          11\n",
       "14         1932    1944          12\n",
       "15         1952    1963          11"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_and_real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
